input {
  # Beats input for Filebeat
  beats {
    port => 5044
  }

  # TCP input for application logs
  tcp {
    port => 5000
    codec => json_lines
  }

  # Syslog input
  syslog {
    port => 5514
  }

  # GELF input for Docker logs
  gelf {
    port => 12201
  }

  # HTTP input for webhook logs
  http {
    port => 8080
    codec => json
  }
}

filter {
  # Parse container logs from Docker
  if [container] {
    mutate {
      add_field => { "log_source" => "docker" }
    }
    
    # Extract service name from container name
    if [container][name] {
      grok {
        match => { "[container][name]" => "^/?(?<service_name>[^-]+)" }
      }
    }
  }

  # Parse application logs
  if [fields][log_type] == "application" {
    # Parse JSON logs
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
      }
    }

    # Parse structured logs
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:logger}: %{GREEDYDATA:log_message}"
      }
    }

    # Parse HTTP access logs
    if [fields][log_type] == "access" {
      grok {
        match => { 
          "message" => "%{COMBINEDAPACHELOG}"
        }
      }
    }

    # Parse API logs
    if [service_name] == "taskmanagement-api" {
      grok {
        match => { 
          "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:component}: %{DATA:method} %{URIPATH:path} - %{NUMBER:status_code} - %{NUMBER:response_time}ms"
        }
      }

      # Convert response time to number
      if [response_time] {
        mutate {
          convert => { "response_time" => "integer" }
        }
      }

      # Convert status code to number
      if [status_code] {
        mutate {
          convert => { "status_code" => "integer" }
        }
      }
    }

    # Parse database logs
    if [service_name] == "postgres" {
      grok {
        match => { 
          "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{NUMBER:pid}\] %{LOGLEVEL:level}: %{GREEDYDATA:log_message}"
        }
      }
    }

    # Parse Redis logs
    if [service_name] == "redis" {
      grok {
        match => { 
          "message" => "%{NUMBER:pid}:%{CHAR:role} %{TIMESTAMP_ISO8601:timestamp} %{CHAR:level} %{GREEDYDATA:log_message}"
        }
      }
    }
  }

  # Parse error logs
  if [level] == "ERROR" or [level] == "error" {
    mutate {
      add_tag => ["error"]
    }

    # Extract stack traces
    if [message] =~ /.*Exception.*/ or [message] =~ /.*Error.*/ {
      mutate {
        add_tag => ["exception"]
      }
    }
  }

  # Parse security logs
  if [fields][log_type] == "security" or [logger] =~ /.*auth.*/ or [logger] =~ /.*security.*/ {
    mutate {
      add_tag => ["security"]
    }

    # Parse authentication events
    if [message] =~ /.*login.*/ or [message] =~ /.*authentication.*/ {
      grok {
        match => { 
          "message" => ".*user:(?<user_id>[^\\s]+).*ip:(?<client_ip>[^\\s]+).*result:(?<auth_result>[^\\s]+)"
        }
      }
      
      mutate {
        add_tag => ["authentication"]
      }
    }
  }

  # Parse performance logs
  if [response_time] {
    if [response_time] > 1000 {
      mutate {
        add_tag => ["slow_request"]
      }
    }
  }

  # Add environment information
  mutate {
    add_field => { "environment" => "${ENVIRONMENT:development}" }
    add_field => { "cluster" => "taskmanagement" }
  }

  # Parse timestamp
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }

  # Normalize log levels
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input", "log" ]
  }

  # GeoIP lookup for client IPs
  if [client_ip] and [client_ip] !~ /^(10\.|192\.168\.|172\.(1[6-9]|2[0-9]|3[01])\.|127\.)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    
    # Index based on log type and date
    index => "taskmanagement-logs-%{+YYYY.MM.dd}"
    
    # Use document type based on service
    document_type => "_doc"
    
    # Template for index mapping
    template_name => "taskmanagement-logs"
    template_pattern => "taskmanagement-logs-*"
    template => "/usr/share/logstash/templates/taskmanagement-logs.json"
    template_overwrite => true
  }

  # Output errors to separate index
  if "error" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "taskmanagement-errors-%{+YYYY.MM.dd}"
    }
  }

  # Output security events to separate index
  if "security" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "taskmanagement-security-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (remove in production)
  if "${LOG_DEBUG:false}" == "true" {
    stdout {
      codec => rubydebug
    }
  }
}