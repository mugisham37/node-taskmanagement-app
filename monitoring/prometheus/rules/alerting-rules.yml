groups:
  # Infrastructure Alerts
  - name: infrastructure.rules
    rules:
      # High CPU Usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High CPU usage detected on {{ $labels.instance }}"
          description: "CPU usage is above 80% for more than 5 minutes on {{ $labels.instance }}. Current value: {{ $value }}%"

      # Critical CPU Usage
      - alert: CriticalCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
        for: 2m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Critical CPU usage detected on {{ $labels.instance }}"
          description: "CPU usage is above 95% for more than 2 minutes on {{ $labels.instance }}. Current value: {{ $value }}%"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High memory usage detected on {{ $labels.instance }}"
          description: "Memory usage is above 80% for more than 5 minutes on {{ $labels.instance }}. Current value: {{ $value }}%"

      # Critical Memory Usage
      - alert: CriticalMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
        for: 2m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Critical memory usage detected on {{ $labels.instance }}"
          description: "Memory usage is above 95% for more than 2 minutes on {{ $labels.instance }}. Current value: {{ $value }}%"

      # High Disk Usage
      - alert: HighDiskUsage
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High disk usage detected on {{ $labels.instance }}"
          description: "Disk usage is above 80% for more than 5 minutes on {{ $labels.instance }} ({{ $labels.mountpoint }}). Current value: {{ $value }}%"

      # Critical Disk Usage
      - alert: CriticalDiskUsage
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 95
        for: 2m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Critical disk usage detected on {{ $labels.instance }}"
          description: "Disk usage is above 95% for more than 2 minutes on {{ $labels.instance }} ({{ $labels.mountpoint }}). Current value: {{ $value }}%"

      # Service Down
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} on {{ $labels.instance }} has been down for more than 1 minute"

  # Application Alerts
  - name: application.rules
    rules:
      # High Response Time
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="taskmanagement-api"}[5m])) > 1
        for: 5m
        labels:
          severity: warning
          service: api
        annotations:
          summary: "High API response time detected"
          description: "95th percentile response time is above 1 second for more than 5 minutes. Current value: {{ $value }}s"

      # Critical Response Time
      - alert: CriticalResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="taskmanagement-api"}[5m])) > 5
        for: 2m
        labels:
          severity: critical
          service: api
        annotations:
          summary: "Critical API response time detected"
          description: "95th percentile response time is above 5 seconds for more than 2 minutes. Current value: {{ $value }}s"

      # High Error Rate
      - alert: HighErrorRate
        expr: rate(http_requests_total{job="taskmanagement-api",status=~"5.."}[5m]) / rate(http_requests_total{job="taskmanagement-api"}[5m]) * 100 > 5
        for: 5m
        labels:
          severity: warning
          service: api
        annotations:
          summary: "High API error rate detected"
          description: "API error rate is above 5% for more than 5 minutes. Current value: {{ $value }}%"

      # Critical Error Rate
      - alert: CriticalErrorRate
        expr: rate(http_requests_total{job="taskmanagement-api",status=~"5.."}[5m]) / rate(http_requests_total{job="taskmanagement-api"}[5m]) * 100 > 20
        for: 2m
        labels:
          severity: critical
          service: api
        annotations:
          summary: "Critical API error rate detected"
          description: "API error rate is above 20% for more than 2 minutes. Current value: {{ $value }}%"

      # Low Request Rate (Possible Service Issue)
      - alert: LowRequestRate
        expr: rate(http_requests_total{job="taskmanagement-api"}[5m]) < 0.1
        for: 10m
        labels:
          severity: warning
          service: api
        annotations:
          summary: "Low API request rate detected"
          description: "API request rate is below 0.1 requests/second for more than 10 minutes. Current value: {{ $value }} req/s"

      # High Memory Usage (Application)
      - alert: HighApplicationMemoryUsage
        expr: process_resident_memory_bytes{job="taskmanagement-api"} / 1024 / 1024 > 512
        for: 5m
        labels:
          severity: warning
          service: api
        annotations:
          summary: "High application memory usage detected"
          description: "Application memory usage is above 512MB for more than 5 minutes. Current value: {{ $value }}MB"

  # Database Alerts
  - name: database.rules
    rules:
      # Database Connection Issues
      - alert: DatabaseConnectionIssues
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          service: database
        annotations:
          summary: "Database connection issues detected"
          description: "Cannot connect to PostgreSQL database for more than 1 minute"

      # High Database Connections
      - alert: HighDatabaseConnections
        expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "High database connection usage detected"
          description: "Database connection usage is above 80% for more than 5 minutes. Current value: {{ $value }}%"

      # Slow Database Queries
      - alert: SlowDatabaseQueries
        expr: pg_stat_activity_max_tx_duration > 300
        for: 2m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Slow database queries detected"
          description: "Database queries running for more than 5 minutes detected"

      # Database Deadlocks
      - alert: DatabaseDeadlocks
        expr: increase(pg_stat_database_deadlocks[5m]) > 0
        for: 0m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Database deadlocks detected"
          description: "{{ $value }} database deadlocks detected in the last 5 minutes"

      # High Database CPU Usage
      - alert: HighDatabaseCPUUsage
        expr: rate(pg_stat_bgwriter_checkpoint_write_time[5m]) > 1000
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "High database CPU usage detected"
          description: "Database checkpoint write time is high, indicating potential CPU issues"

  # Cache Alerts (Redis)
  - name: cache.rules
    rules:
      # Redis Connection Issues
      - alert: RedisConnectionIssues
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          service: cache
        annotations:
          summary: "Redis connection issues detected"
          description: "Cannot connect to Redis cache for more than 1 minute"

      # High Redis Memory Usage
      - alert: HighRedisMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: cache
        annotations:
          summary: "High Redis memory usage detected"
          description: "Redis memory usage is above 80% for more than 5 minutes. Current value: {{ $value }}%"

      # Redis Slow Queries
      - alert: RedisSlowQueries
        expr: redis_slowlog_length > 10
        for: 5m
        labels:
          severity: warning
          service: cache
        annotations:
          summary: "Redis slow queries detected"
          description: "Redis slow log has more than 10 entries for more than 5 minutes"

      # High Redis Connection Count
      - alert: HighRedisConnections
        expr: redis_connected_clients > 100
        for: 5m
        labels:
          severity: warning
          service: cache
        annotations:
          summary: "High Redis connection count detected"
          description: "Redis has more than 100 connected clients for more than 5 minutes. Current value: {{ $value }}"

  # Business Metrics Alerts
  - name: business.rules
    rules:
      # Low User Registration Rate
      - alert: LowUserRegistrationRate
        expr: rate(user_registrations_total[1h]) < 0.01
        for: 2h
        labels:
          severity: warning
          service: business
        annotations:
          summary: "Low user registration rate detected"
          description: "User registration rate is below 0.01 registrations/hour for more than 2 hours"

      # High Task Creation Failure Rate
      - alert: HighTaskCreationFailureRate
        expr: rate(task_creation_failures_total[5m]) / rate(task_creation_attempts_total[5m]) * 100 > 10
        for: 10m
        labels:
          severity: warning
          service: business
        annotations:
          summary: "High task creation failure rate detected"
          description: "Task creation failure rate is above 10% for more than 10 minutes. Current value: {{ $value }}%"

      # Low Daily Active Users
      - alert: LowDailyActiveUsers
        expr: daily_active_users < 10
        for: 1h
        labels:
          severity: warning
          service: business
        annotations:
          summary: "Low daily active users detected"
          description: "Daily active users count is below 10 for more than 1 hour. Current value: {{ $value }}"

      # High Authentication Failure Rate
      - alert: HighAuthenticationFailureRate
        expr: rate(authentication_failures_total[5m]) / rate(authentication_attempts_total[5m]) * 100 > 20
        for: 5m
        labels:
          severity: warning
          service: auth
        annotations:
          summary: "High authentication failure rate detected"
          description: "Authentication failure rate is above 20% for more than 5 minutes. Current value: {{ $value }}%"

  # Security Alerts
  - name: security.rules
    rules:
      # Suspicious Login Activity
      - alert: SuspiciousLoginActivity
        expr: rate(failed_login_attempts_total[5m]) > 10
        for: 2m
        labels:
          severity: warning
          service: auth
        annotations:
          summary: "Suspicious login activity detected"
          description: "High rate of failed login attempts detected: {{ $value }} attempts/second"

      # Multiple Failed Login Attempts from Same IP
      - alert: MultipleFailedLoginAttempts
        expr: increase(failed_login_attempts_total[10m]) by (source_ip) > 20
        for: 0m
        labels:
          severity: critical
          service: auth
        annotations:
          summary: "Multiple failed login attempts from same IP"
          description: "More than 20 failed login attempts from IP {{ $labels.source_ip }} in the last 10 minutes"

      # Unusual API Access Patterns
      - alert: UnusualAPIAccessPatterns
        expr: rate(http_requests_total{status=~"4.."}[5m]) > 5
        for: 5m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "Unusual API access patterns detected"
          description: "High rate of 4xx HTTP responses detected: {{ $value }} requests/second"

      # Potential DDoS Attack
      - alert: PotentialDDoSAttack
        expr: rate(http_requests_total[1m]) > 1000
        for: 2m
        labels:
          severity: critical
          service: security
        annotations:
          summary: "Potential DDoS attack detected"
          description: "Extremely high request rate detected: {{ $value }} requests/second"

  # Monitoring Stack Alerts
  - name: monitoring.rules
    rules:
      # Prometheus Target Down
      - alert: PrometheusTargetDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
          service: monitoring
        annotations:
          summary: "Prometheus target is down"
          description: "Prometheus target {{ $labels.instance }} has been down for more than 1 minute"

      # Grafana Down
      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 1m
        labels:
          severity: critical
          service: monitoring
        annotations:
          summary: "Grafana is down"
          description: "Grafana has been down for more than 1 minute"

      # AlertManager Down
      - alert: AlertManagerDown
        expr: up{job="alertmanager"} == 0
        for: 1m
        labels:
          severity: critical
          service: monitoring
        annotations:
          summary: "AlertManager is down"
          description: "AlertManager has been down for more than 1 minute"

      # High Prometheus Memory Usage
      - alert: HighPrometheusMemoryUsage
        expr: process_resident_memory_bytes{job="prometheus"} / 1024 / 1024 / 1024 > 2
        for: 5m
        labels:
          severity: warning
          service: monitoring
        annotations:
          summary: "High Prometheus memory usage"
          description: "Prometheus memory usage is above 2GB for more than 5 minutes. Current value: {{ $value }}GB"