name: Performance Testing

on:
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      duration:
        description: 'Test duration (minutes)'
        required: true
        default: '5'
      users:
        description: 'Number of virtual users'
        required: true
        default: '50'

env:
  NODE_VERSION: '18'
  PNPM_VERSION: '8'

jobs:
  # API Load Testing
  api-load-test:
    name: API Load Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup K6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Determine test environment
        id: env
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "base_url=https://${{ github.event.inputs.environment }}-api.taskmanagement.app" >> $GITHUB_OUTPUT
            echo "duration=${{ github.event.inputs.duration }}m" >> $GITHUB_OUTPUT
            echo "users=${{ github.event.inputs.users }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "base_url=https://staging-api.taskmanagement.app" >> $GITHUB_OUTPUT
            echo "duration=5m" >> $GITHUB_OUTPUT
            echo "users=50" >> $GITHUB_OUTPUT
          else
            echo "base_url=http://localhost:3000" >> $GITHUB_OUTPUT
            echo "duration=2m" >> $GITHUB_OUTPUT
            echo "users=20" >> $GITHUB_OUTPUT
          fi

      - name: Start local API (for PR tests)
        if: github.event_name == 'pull_request'
        run: |
          # Setup test environment
          docker-compose -f docker-compose.test.yml up -d
          
          # Wait for services to be ready
          timeout 60 bash -c 'until curl -f http://localhost:3000/health; do sleep 2; done'

      - name: Run API load tests
        run: |
          k6 run tests/performance/api-load-test.js \
            --env BASE_URL=${{ steps.env.outputs.base_url }} \
            --env DURATION=${{ steps.env.outputs.duration }} \
            --env USERS=${{ steps.env.outputs.users }} \
            --out json=api-performance-results.json

      - name: Upload API performance results
        uses: actions/upload-artifact@v3
        with:
          name: api-performance-results
          path: api-performance-results.json

      - name: Analyze API performance results
        run: |
          # Extract key metrics from K6 results
          cat api-performance-results.json | jq -r '
            select(.type == "Point" and .metric == "http_req_duration") |
            .data.value
          ' | awk '
            {
              sum += $1
              count++
              if ($1 > max) max = $1
              if (min == 0 || $1 < min) min = $1
            }
            END {
              avg = sum / count
              print "Average response time: " avg "ms"
              print "Min response time: " min "ms"
              print "Max response time: " max "ms"
            }
          ' > api-performance-summary.txt

      - name: Comment performance results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('api-performance-summary.txt', 'utf8');
            
            const comment = `## ðŸš€ API Performance Test Results
            
            ${summary}
            
            **Test Configuration:**
            - Duration: ${{ steps.env.outputs.duration }}
            - Virtual Users: ${{ steps.env.outputs.users }}
            - Environment: Local
            
            <details>
            <summary>View detailed results</summary>
            
            Full performance results are available in the workflow artifacts.
            
            </details>`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Frontend Performance Testing
  frontend-performance:
    name: Frontend Performance Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build applications
        run: |
          pnpm run build --filter=@taskmanagement/web
          pnpm run build --filter=@taskmanagement/admin

      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli@0.12.x

      - name: Start applications for testing
        if: github.event_name == 'pull_request'
        run: |
          # Start web app
          cd apps/web && pnpm start &
          WEB_PID=$!
          
          # Start admin app
          cd apps/admin && pnpm start &
          ADMIN_PID=$!
          
          # Wait for apps to be ready
          timeout 60 bash -c 'until curl -f http://localhost:3000; do sleep 2; done'
          timeout 60 bash -c 'until curl -f http://localhost:3001; do sleep 2; done'
          
          echo "WEB_PID=$WEB_PID" >> $GITHUB_ENV
          echo "ADMIN_PID=$ADMIN_PID" >> $GITHUB_ENV

      - name: Run Lighthouse CI
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            # Test local builds
            lhci autorun --config=.lighthouserc.json
          else
            # Test staging environment
            lhci autorun --config=.lighthouserc.staging.json
          fi

      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v3
        with:
          name: lighthouse-results
          path: .lighthouseci/

      - name: Analyze bundle sizes
        run: |
          # Analyze bundle sizes for web app
          cd apps/web
          npx webpack-bundle-analyzer dist/static/js/*.js --mode json > ../../web-bundle-analysis.json
          
          # Analyze bundle sizes for admin app
          cd ../admin
          npx webpack-bundle-analyzer dist/static/js/*.js --mode json > ../../admin-bundle-analysis.json

      - name: Upload bundle analysis
        uses: actions/upload-artifact@v3
        with:
          name: bundle-analysis
          path: |
            web-bundle-analysis.json
            admin-bundle-analysis.json

      - name: Stop applications
        if: always() && github.event_name == 'pull_request'
        run: |
          kill $WEB_PID $ADMIN_PID || true

  # Database Performance Testing
  database-performance:
    name: Database Performance Testing
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: taskmanagement_perf_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Setup test database
        run: |
          # Run migrations
          pnpm run db:migrate
          
          # Seed with performance test data
          pnpm run db:seed:performance
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/taskmanagement_perf_test

      - name: Run database performance tests
        run: |
          pnpm run test:performance:database
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/taskmanagement_perf_test

      - name: Upload database performance results
        uses: actions/upload-artifact@v3
        with:
          name: database-performance-results
          path: database-performance-results.json

  # Memory and CPU Profiling
  profiling:
    name: Memory & CPU Profiling
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install profiling tools
        run: |
          npm install -g clinic
          npm install -g autocannon

      - name: Build API
        run: pnpm run build --filter=@taskmanagement/api

      - name: Run CPU profiling
        run: |
          cd apps/api
          
          # Start API with CPU profiling
          clinic doctor --on-port 'autocannon -c 10 -d 30 http://localhost:3000/health' -- node dist/index.js
          
          # Move results
          mv .clinic/* ../../cpu-profile/

      - name: Run memory profiling
        run: |
          cd apps/api
          
          # Start API with memory profiling
          clinic heapprofiler --on-port 'autocannon -c 10 -d 30 http://localhost:3000/health' -- node dist/index.js
          
          # Move results
          mv .clinic/* ../../memory-profile/

      - name: Upload profiling results
        uses: actions/upload-artifact@v3
        with:
          name: profiling-results
          path: |
            cpu-profile/
            memory-profile/

  # Performance regression detection
  regression-detection:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    needs: [api-load-test, frontend-performance, database-performance]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download performance results
        uses: actions/download-artifact@v3

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install analysis tools
        run: |
          npm install -g performance-budgets-cli

      - name: Analyze performance trends
        run: |
          # Create performance comparison report
          cat > performance-analysis.js << 'EOF'
          const fs = require('fs');
          
          // Load current results
          const apiResults = JSON.parse(fs.readFileSync('api-performance-results/api-performance-results.json', 'utf8'));
          
          // Calculate key metrics
          const responseTime = apiResults
            .filter(r => r.type === 'Point' && r.metric === 'http_req_duration')
            .map(r => r.data.value);
          
          const avgResponseTime = responseTime.reduce((a, b) => a + b, 0) / responseTime.length;
          const p95ResponseTime = responseTime.sort((a, b) => a - b)[Math.floor(responseTime.length * 0.95)];
          
          console.log(`Average Response Time: ${avgResponseTime.toFixed(2)}ms`);
          console.log(`P95 Response Time: ${p95ResponseTime.toFixed(2)}ms`);
          
          // Performance thresholds
          const thresholds = {
            avgResponseTime: 500, // 500ms
            p95ResponseTime: 1000 // 1000ms
          };
          
          let regressionDetected = false;
          
          if (avgResponseTime > thresholds.avgResponseTime) {
            console.log(`âš ï¸ Performance regression: Average response time (${avgResponseTime.toFixed(2)}ms) exceeds threshold (${thresholds.avgResponseTime}ms)`);
            regressionDetected = true;
          }
          
          if (p95ResponseTime > thresholds.p95ResponseTime) {
            console.log(`âš ï¸ Performance regression: P95 response time (${p95ResponseTime.toFixed(2)}ms) exceeds threshold (${thresholds.p95ResponseTime}ms)`);
            regressionDetected = true;
          }
          
          if (!regressionDetected) {
            console.log('âœ… No performance regressions detected');
          }
          
          process.exit(regressionDetected ? 1 : 0);
          EOF
          
          node performance-analysis.js

      - name: Create performance report
        if: always()
        run: |
          cat > performance-report.md << 'EOF'
          # Performance Test Report
          
          **Test Date:** $(date)
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          
          ## Test Results Summary
          
          | Test Type | Status | Notes |
          |-----------|--------|-------|
          | API Load Test | ${{ needs.api-load-test.result }} | Load testing with K6 |
          | Frontend Performance | ${{ needs.frontend-performance.result }} | Lighthouse CI analysis |
          | Database Performance | ${{ needs.database-performance.result }} | Query performance testing |
          
          ## Key Metrics
          
          - **API Response Time**: See detailed results in artifacts
          - **Lighthouse Scores**: See detailed results in artifacts
          - **Database Query Performance**: See detailed results in artifacts
          
          ## Recommendations
          
          1. Monitor response times and optimize slow endpoints
          2. Review Lighthouse recommendations for frontend optimization
          3. Optimize database queries that exceed performance thresholds
          4. Consider caching strategies for frequently accessed data
          
          EOF

      - name: Upload performance report
        uses: actions/upload-artifact@v3
        with:
          name: performance-report
          path: performance-report.md

  # Notification
  notify-performance:
    name: Notify Performance Results
    runs-on: ubuntu-latest
    needs: [api-load-test, frontend-performance, database-performance, regression-detection]
    if: always() && (failure() || github.event_name == 'schedule')
    steps:
      - name: Notify team about performance issues
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#performance'
          text: |
            âš ï¸ Performance regression detected in ${{ github.repository }}!
            
            Failed tests:
            - API Load Test: ${{ needs.api-load-test.result }}
            - Frontend Performance: ${{ needs.frontend-performance.result }}
            - Database Performance: ${{ needs.database-performance.result }}
            - Regression Detection: ${{ needs.regression-detection.result }}
            
            Please review the performance test results and optimize accordingly.
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify daily performance summary
        if: github.event_name == 'schedule'
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#performance'
          text: |
            ðŸ“Š Daily performance test summary for ${{ github.repository }}:
            
            Results:
            - API Load Test: ${{ needs.api-load-test.result }}
            - Frontend Performance: ${{ needs.frontend-performance.result }}
            - Database Performance: ${{ needs.database-performance.result }}
            - Regression Detection: ${{ needs.regression-detection.result }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}