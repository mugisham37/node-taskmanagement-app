name: Backup and Disaster Recovery

on:
  schedule:
    - cron: '0 1 * * *' # Daily at 1 AM UTC
    - cron: '0 1 * * 0' # Weekly full backup on Sunday
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup to perform'
        required: true
        default: 'incremental'
        type: choice
        options:
          - incremental
          - full
          - differential
      environment:
        description: 'Environment to backup'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
      restore_point:
        description: 'Restore point timestamp (for restore operations)'
        required: false
        type: string

env:
  BACKUP_RETENTION_DAYS: 30
  FULL_BACKUP_RETENTION_DAYS: 90

jobs:
  database-backup:
    name: Database Backup
    runs-on: ubuntu-latest
    if: github.event.inputs.restore_point == ''
    strategy:
      matrix:
        environment: [production, staging]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          mkdir -p ~/.kube
          if [ "${{ matrix.environment }}" == "production" ]; then
            echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > ~/.kube/config
          else
            echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > ~/.kube/config
          fi
          chmod 600 ~/.kube/config

      - name: Determine backup type
        id: backup-type
        run: |
          if [ "${{ github.event.inputs.backup_type }}" != "" ]; then
            echo "type=${{ github.event.inputs.backup_type }}" >> $GITHUB_OUTPUT
          elif [ "$(date +%u)" == "7" ]; then
            echo "type=full" >> $GITHUB_OUTPUT
          else
            echo "type=incremental" >> $GITHUB_OUTPUT
          fi

      - name: Create database backup job
        run: |
          BACKUP_NAME="db-backup-${{ matrix.environment }}-$(date +%Y%m%d-%H%M%S)"
          BACKUP_TYPE="${{ steps.backup-type.outputs.type }}"
          
          kubectl create job $BACKUP_NAME \
            --from=cronjob/database-backup-$BACKUP_TYPE \
            --namespace=taskmanagement-${{ matrix.environment }}

      - name: Wait for backup completion
        run: |
          BACKUP_NAME="db-backup-${{ matrix.environment }}-$(date +%Y%m%d-%H%M%S)"
          kubectl wait --for=condition=complete --timeout=3600s job/$BACKUP_NAME \
            --namespace=taskmanagement-${{ matrix.environment }}

      - name: Verify backup integrity
        run: |
          kubectl run backup-verify-$(date +%s) \
            --image=postgres:15 \
            --restart=Never \
            --namespace=taskmanagement-${{ matrix.environment }} \
            --env="BACKUP_NAME=db-backup-${{ matrix.environment }}-$(date +%Y%m%d-%H%M%S)" \
            --command -- /scripts/verify-backup.sh

      - name: Upload backup to S3
        run: |
          kubectl run backup-upload-$(date +%s) \
            --image=amazon/aws-cli:latest \
            --restart=Never \
            --namespace=taskmanagement-${{ matrix.environment }} \
            --env="AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" \
            --env="AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            --env="BACKUP_NAME=db-backup-${{ matrix.environment }}-$(date +%Y%m%d-%H%M%S)" \
            --command -- aws s3 cp /backups/$BACKUP_NAME.sql.gz s3://taskmanagement-backups/${{ matrix.environment }}/database/

      - name: Clean old backups
        run: |
          kubectl run backup-cleanup-$(date +%s) \
            --image=amazon/aws-cli:latest \
            --restart=Never \
            --namespace=taskmanagement-${{ matrix.environment }} \
            --env="AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" \
            --env="AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            --env="RETENTION_DAYS=${{ env.BACKUP_RETENTION_DAYS }}" \
            --command -- /scripts/cleanup-old-backups.sh

  file-storage-backup:
    name: File Storage Backup
    runs-on: ubuntu-latest
    if: github.event.inputs.restore_point == ''
    strategy:
      matrix:
        environment: [production, staging]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Sync file storage to backup bucket
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Sync user uploads
          aws s3 sync s3://taskmanagement-uploads-${{ matrix.environment }} \
            s3://taskmanagement-backups/${{ matrix.environment }}/files/$TIMESTAMP/uploads/ \
            --delete

          # Sync static assets
          aws s3 sync s3://taskmanagement-assets-${{ matrix.environment }} \
            s3://taskmanagement-backups/${{ matrix.environment }}/files/$TIMESTAMP/assets/ \
            --delete

      - name: Create backup manifest
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          cat > backup-manifest.json << EOF
          {
            "timestamp": "$TIMESTAMP",
            "environment": "${{ matrix.environment }}",
            "type": "file-storage",
            "backup_type": "${{ steps.backup-type.outputs.type }}",
            "size": "$(aws s3 ls s3://taskmanagement-backups/${{ matrix.environment }}/files/$TIMESTAMP/ --recursive --summarize | grep 'Total Size' | awk '{print $3}')",
            "file_count": "$(aws s3 ls s3://taskmanagement-backups/${{ matrix.environment }}/files/$TIMESTAMP/ --recursive --summarize | grep 'Total Objects' | awk '{print $3}')"
          }
          EOF

          aws s3 cp backup-manifest.json \
            s3://taskmanagement-backups/${{ matrix.environment }}/files/$TIMESTAMP/manifest.json

  configuration-backup:
    name: Configuration Backup
    runs-on: ubuntu-latest
    if: github.event.inputs.restore_point == ''
    strategy:
      matrix:
        environment: [production, staging]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          mkdir -p ~/.kube
          if [ "${{ matrix.environment }}" == "production" ]; then
            echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > ~/.kube/config
          else
            echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > ~/.kube/config
          fi
          chmod 600 ~/.kube/config

      - name: Backup Kubernetes configurations
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          BACKUP_DIR="k8s-backup-$TIMESTAMP"
          mkdir -p $BACKUP_DIR

          # Backup all resources in the namespace
          kubectl get all -o yaml --namespace=taskmanagement-${{ matrix.environment }} > $BACKUP_DIR/all-resources.yaml
          kubectl get configmaps -o yaml --namespace=taskmanagement-${{ matrix.environment }} > $BACKUP_DIR/configmaps.yaml
          kubectl get secrets -o yaml --namespace=taskmanagement-${{ matrix.environment }} > $BACKUP_DIR/secrets.yaml
          kubectl get ingress -o yaml --namespace=taskmanagement-${{ matrix.environment }} > $BACKUP_DIR/ingress.yaml
          kubectl get pvc -o yaml --namespace=taskmanagement-${{ matrix.environment }} > $BACKUP_DIR/pvc.yaml

          # Create archive
          tar -czf $BACKUP_DIR.tar.gz $BACKUP_DIR/

      - name: Upload configuration backup
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Upload to S3
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          aws s3 cp k8s-backup-$TIMESTAMP.tar.gz \
            s3://taskmanagement-backups/${{ matrix.environment }}/configurations/k8s-backup-$TIMESTAMP.tar.gz

  disaster-recovery-test:
    name: Disaster Recovery Test
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' && github.event.schedule == '0 1 * * 0'
    needs: [database-backup, file-storage-backup, configuration-backup]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup test environment
        run: |
          # Create isolated test namespace
          kubectl create namespace dr-test-$(date +%s)

      - name: Restore database from backup
        run: |
          LATEST_BACKUP=$(aws s3 ls s3://taskmanagement-backups/production/database/ | sort | tail -n 1 | awk '{print $4}')
          
          kubectl run db-restore-test-$(date +%s) \
            --image=postgres:15 \
            --restart=Never \
            --namespace=dr-test-$(date +%s) \
            --env="BACKUP_FILE=$LATEST_BACKUP" \
            --command -- /scripts/restore-database.sh

      - name: Validate restored data
        run: |
          kubectl run data-validation-$(date +%s) \
            --image=postgres:15 \
            --restart=Never \
            --namespace=dr-test-$(date +%s) \
            --command -- /scripts/validate-restored-data.sh

      - name: Test application functionality
        run: |
          # Deploy minimal application stack for testing
          kubectl apply -f infrastructure/kubernetes/dr-test/ --namespace=dr-test-$(date +%s)
          
          # Wait for deployment
          kubectl rollout status deployment/taskmanagement-api --namespace=dr-test-$(date +%s) --timeout=300s
          
          # Run basic functionality tests
          kubectl run functionality-test-$(date +%s) \
            --image=curlimages/curl:latest \
            --restart=Never \
            --namespace=dr-test-$(date +%s) \
            --command -- /scripts/test-basic-functionality.sh

      - name: Cleanup test environment
        if: always()
        run: |
          kubectl delete namespace dr-test-$(date +%s) --ignore-not-found=true

      - name: Generate DR test report
        run: |
          cat > dr-test-report.md << EOF
          # Disaster Recovery Test Report
          
          **Date**: $(date)
          **Status**: ${{ job.status }}
          
          ## Test Results
          - Database restore: ✅ Success
          - Data validation: ✅ Success
          - Application functionality: ✅ Success
          
          ## Recovery Time Objective (RTO)
          - Target: 4 hours
          - Actual: $(cat rto-measurement.txt)
          
          ## Recovery Point Objective (RPO)
          - Target: 1 hour
          - Actual: $(cat rpo-measurement.txt)
          EOF

      - name: Upload DR test report
        uses: actions/upload-artifact@v3
        with:
          name: dr-test-report
          path: dr-test-report.md

  restore-operation:
    name: Restore from Backup
    runs-on: ubuntu-latest
    if: github.event.inputs.restore_point != ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          mkdir -p ~/.kube
          if [ "${{ github.event.inputs.environment }}" == "production" ]; then
            echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > ~/.kube/config
          else
            echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > ~/.kube/config
          fi
          chmod 600 ~/.kube/config

      - name: Validate restore point
        run: |
          RESTORE_POINT="${{ github.event.inputs.restore_point }}"
          
          # Check if backup exists
          aws s3 ls s3://taskmanagement-backups/${{ github.event.inputs.environment }}/database/db-backup-$RESTORE_POINT.sql.gz
          
          if [ $? -ne 0 ]; then
            echo "Backup not found for restore point: $RESTORE_POINT"
            exit 1
          fi

      - name: Create maintenance mode
        run: |
          kubectl patch deployment taskmanagement-api \
            --patch '{"spec":{"replicas":0}}' \
            --namespace=taskmanagement-${{ github.event.inputs.environment }}
          
          kubectl patch deployment taskmanagement-web \
            --patch '{"spec":{"replicas":0}}' \
            --namespace=taskmanagement-${{ github.event.inputs.environment }}
          
          kubectl patch deployment taskmanagement-admin \
            --patch '{"spec":{"replicas":0}}' \
            --namespace=taskmanagement-${{ github.event.inputs.environment }}

      - name: Restore database
        run: |
          RESTORE_POINT="${{ github.event.inputs.restore_point }}"
          
          kubectl run db-restore-$(date +%s) \
            --image=postgres:15 \
            --restart=Never \
            --namespace=taskmanagement-${{ github.event.inputs.environment }} \
            --env="RESTORE_POINT=$RESTORE_POINT" \
            --env="AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" \
            --env="AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            --command -- /scripts/restore-database.sh

      - name: Restore file storage
        run: |
          RESTORE_POINT="${{ github.event.inputs.restore_point }}"
          
          # Restore user uploads
          aws s3 sync s3://taskmanagement-backups/${{ github.event.inputs.environment }}/files/$RESTORE_POINT/uploads/ \
            s3://taskmanagement-uploads-${{ github.event.inputs.environment }} \
            --delete

          # Restore static assets
          aws s3 sync s3://taskmanagement-backups/${{ github.event.inputs.environment }}/files/$RESTORE_POINT/assets/ \
            s3://taskmanagement-assets-${{ github.event.inputs.environment }} \
            --delete

      - name: Validate restored data
        run: |
          kubectl run data-validation-$(date +%s) \
            --image=postgres:15 \
            --restart=Never \
            --namespace=taskmanagement-${{ github.event.inputs.environment }} \
            --command -- /scripts/validate-restored-data.sh

      - name: Exit maintenance mode
        run: |
          kubectl patch deployment taskmanagement-api \
            --patch '{"spec":{"replicas":3}}' \
            --namespace=taskmanagement-${{ github.event.inputs.environment }}
          
          kubectl patch deployment taskmanagement-web \
            --patch '{"spec":{"replicas":2}}' \
            --namespace=taskmanagement-${{ github.event.inputs.environment }}
          
          kubectl patch deployment taskmanagement-admin \
            --patch '{"spec":{"replicas":2}}' \
            --namespace=taskmanagement-${{ github.event.inputs.environment }}

      - name: Wait for services to be ready
        run: |
          kubectl rollout status deployment/taskmanagement-api --namespace=taskmanagement-${{ github.event.inputs.environment }} --timeout=600s
          kubectl rollout status deployment/taskmanagement-web --namespace=taskmanagement-${{ github.event.inputs.environment }} --timeout=600s
          kubectl rollout status deployment/taskmanagement-admin --namespace=taskmanagement-${{ github.event.inputs.environment }} --timeout=600s

      - name: Run post-restore tests
        run: |
          npm ci
          npm run test:post-restore
        env:
          TEST_ENVIRONMENT: ${{ github.event.inputs.environment }}

      - name: Notify restore completion
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: "🔄 Restore operation completed for ${{ github.event.inputs.environment }} environment from restore point ${{ github.event.inputs.restore_point }}"
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  backup-monitoring:
    name: Backup Monitoring and Alerting
    runs-on: ubuntu-latest
    needs: [database-backup, file-storage-backup, configuration-backup]
    if: always()
    steps:
      - name: Check backup status
        run: |
          # Check if all backup jobs completed successfully
          if [ "${{ needs.database-backup.result }}" != "success" ] || 
             [ "${{ needs.file-storage-backup.result }}" != "success" ] || 
             [ "${{ needs.configuration-backup.result }}" != "success" ]; then
            echo "BACKUP_FAILED=true" >> $GITHUB_ENV
          else
            echo "BACKUP_FAILED=false" >> $GITHUB_ENV
          fi

      - name: Update backup metrics
        run: |
          # Send metrics to monitoring system
          curl -X POST "${{ secrets.METRICS_ENDPOINT }}" \
            -H "Authorization: Bearer ${{ secrets.METRICS_TOKEN }}" \
            -H "Content-Type: application/json" \
            -d '{
              "metric": "backup_status",
              "value": "${{ env.BACKUP_FAILED == 'false' && 1 || 0 }}",
              "timestamp": "'$(date -u +%s)'",
              "tags": {
                "environment": "all",
                "backup_type": "${{ github.event.inputs.backup_type || 'scheduled' }}"
              }
            }'

      - name: Alert on backup failure
        if: env.BACKUP_FAILED == 'true'
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: "🚨 Backup operation failed - immediate attention required"
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_CRITICAL }}

      - name: Generate backup report
        run: |
          cat > backup-report.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "status": "${{ env.BACKUP_FAILED == 'false' && 'success' || 'failed' }}",
            "database_backup": "${{ needs.database-backup.result }}",
            "file_storage_backup": "${{ needs.file-storage-backup.result }}",
            "configuration_backup": "${{ needs.configuration-backup.result }}",
            "backup_type": "${{ github.event.inputs.backup_type || 'scheduled' }}"
          }
          EOF

      - name: Upload backup report
        uses: actions/upload-artifact@v3
        with:
          name: backup-report
          path: backup-report.json